{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746bb70-eb1f-473e-bc2b-97abcf5067f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from model import SingleImageTransformer\n",
    "from dataset import BarLinkageDataset \n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "from curve_plot import get_pca_inclination, rotate_curve\n",
    "import scipy.spatial.distance as sciDist\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354fc90-9448-4531-ad0b-f95058e8fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headless simulator version\n",
    "index = 0 # local server index \n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "speedscale = 1\n",
    "steps = 360\n",
    "minsteps = int(steps*20/360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8ae72c-963c-458f-a536-c6737e88084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"weights/d2048_h32_n6_bs1024_lr0.0001.pth\"\n",
    "data_dir = \"/home/anurizada/Documents/processed_dataset_105\"\n",
    "batch_size = 1\n",
    "\n",
    "dataset = BarLinkageDataset(data_dir=data_dir)\n",
    "dataset = torch.utils.data.Subset(dataset, range(1000000))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4913484-58cd-4236-bc77-e3cf855f884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model_config = checkpoint['model_config']\n",
    "\n",
    "# Initialize model\n",
    "model = SingleImageTransformer(\n",
    "    tgt_seq_len=model_config['tgt_seq_len'],\n",
    "    d_model=model_config['d_model'],\n",
    "    h=model_config['h'],\n",
    "    N=model_config['N'],\n",
    "    num_labels=model_config['num_labels'],\n",
    "    vocab_size=model_config['vocab_size'] + 1,\n",
    ").to(device)\n",
    "\n",
    "# Load weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1fecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "from curve_plot import get_pca_inclination, rotate_curve\n",
    "\n",
    "# ===================================\n",
    "# CONFIGURATION\n",
    "# ===================================\n",
    "label_mapping_path = \"/home/anurizada/Documents/processed_dataset_105/label_mapping.json\"\n",
    "with open(label_mapping_path, \"r\") as f:\n",
    "    label_mapping = json.load(f)\n",
    "index_to_label = label_mapping[\"index_to_label\"]\n",
    "\n",
    "# --- coordinate binning setup ---\n",
    "class CoordinateBinner:\n",
    "    def __init__(self, kappa=1.0, num_bins=200):\n",
    "        self.kappa = kappa\n",
    "        self.num_bins = num_bins\n",
    "        self.bin_edges = np.linspace(-kappa, kappa, num_bins + 1)\n",
    "        self.bin_centers = (self.bin_edges[:-1] + self.bin_edges[1:]) / 2\n",
    "\n",
    "    def bin_to_value_torch(self, bin_index_tensor):\n",
    "        bin_index_tensor = torch.clamp(bin_index_tensor, 0, self.num_bins - 1)\n",
    "        bin_centers_tensor = torch.tensor(self.bin_centers, device=bin_index_tensor.device, dtype=torch.float32)\n",
    "        return bin_centers_tensor[bin_index_tensor]\n",
    "\n",
    "# from your label_mapping.json\n",
    "NUM_BINS = label_mapping[\"num_bins\"]\n",
    "BIN_OFFSET = label_mapping[\"special_tokens\"][\"NUM_SPECIAL_TOKENS\"]  # usually 3\n",
    "binner = CoordinateBinner(kappa=1.0, num_bins=NUM_BINS)\n",
    "\n",
    "print(f\"Loaded label mapping with {len(index_to_label)} mechanism types.\")\n",
    "print(f\"Coordinate binning: {NUM_BINS} bins, BIN_OFFSET={BIN_OFFSET}\")\n",
    "\n",
    "print('Started')\n",
    "start_time = time.time()\n",
    "\n",
    "eos_token = 1\n",
    "pad_token = 2\n",
    "\n",
    "# ===================================\n",
    "# BATCH INFERENCE\n",
    "# ===================================\n",
    "def predict_batch(model, dataloader, max_samples=100, device=\"cuda\"):\n",
    "    all_predictions, all_targets, all_labels = [], [], []\n",
    "    samples_processed = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Running batch inference\"):\n",
    "            if samples_processed >= max_samples:\n",
    "                break\n",
    "\n",
    "            decoder_input = batch[\"decoder_input_discrete\"].to(device)\n",
    "            decoder_mask = batch[\"causal_mask\"].to(device)\n",
    "            images = batch[\"images\"].to(device)\n",
    "            encoded_labels = batch[\"encoded_labels\"].to(device)\n",
    "            target_tokens = batch[\"labels_discrete\"].to(device)\n",
    "\n",
    "            predictions, _, _ = model(decoder_input, decoder_mask, images, encoded_labels)\n",
    "            pred_tokens = predictions.argmax(dim=-1)\n",
    "\n",
    "            for i in range(pred_tokens.shape[0]):\n",
    "                if samples_processed >= max_samples:\n",
    "                    break\n",
    "\n",
    "                pred_seq = pred_tokens[i].cpu().numpy()\n",
    "                target_seq = target_tokens[i].cpu().numpy()\n",
    "\n",
    "                valid_mask = target_seq != pad_token\n",
    "                pred_seq = pred_seq[valid_mask]\n",
    "                target_seq = target_seq[valid_mask]\n",
    "\n",
    "                if eos_token in pred_seq:\n",
    "                    pred_seq = pred_seq[: np.where(pred_seq == eos_token)[0][0]]\n",
    "                if eos_token in target_seq:\n",
    "                    target_seq = target_seq[: np.where(target_seq == eos_token)[0][0]]\n",
    "\n",
    "                # get label index from one-hot or already-int encoded tensor\n",
    "                label_idx = encoded_labels[i].item()\n",
    "\n",
    "                all_predictions.append(pred_seq)\n",
    "                all_targets.append(target_seq)\n",
    "                all_labels.append(label_idx)\n",
    "                samples_processed += 1\n",
    "\n",
    "    print(f\"\\nProcessed {samples_processed} samples total\")\n",
    "    return all_predictions, all_targets, all_labels\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# RUN INFERENCE\n",
    "# ===================================\n",
    "max_samples = 20\n",
    "predictions, targets, label_indices = predict_batch(model, dataloader, max_samples=max_samples, device=device)\n",
    "print(label_indices)\n",
    "\n",
    "# ===================================\n",
    "# CONVERT BINS → CONTINUOUS COORDINATES\n",
    "# ===================================\n",
    "def bins_to_continuous(seq, binner, bin_offset):\n",
    "    seq = np.array(seq)\n",
    "    # remove special tokens (anything below BIN_OFFSET)\n",
    "    numeric_mask = seq >= bin_offset\n",
    "    seq_numeric = seq[numeric_mask] - bin_offset\n",
    "    seq_tensor = torch.tensor(seq_numeric, dtype=torch.long)\n",
    "    seq_cont = binner.bin_to_value_torch(seq_tensor).cpu().numpy()\n",
    "    return seq_cont\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# SIMULATION LOOP\n",
    "# ===================================\n",
    "for idx, (pred_seq, target_seq, label_idx) in enumerate(zip(predictions, targets, label_indices)):\n",
    "    mech_type = index_to_label[str(label_idx)]\n",
    "\n",
    "    # Convert discrete bins → continuous coords\n",
    "    pred_cont = bins_to_continuous(pred_seq, binner, BIN_OFFSET)\n",
    "    target_cont = bins_to_continuous(target_seq, binner, BIN_OFFSET)\n",
    "\n",
    "    # Drop odd lengths to form (N, 2)\n",
    "    if len(pred_cont) % 2 == 1:\n",
    "        pred_cont = pred_cont[:-1]\n",
    "    if len(target_cont) % 2 == 1:\n",
    "        target_cont = target_cont[:-1]\n",
    "\n",
    "    pred_joints = pred_cont.reshape(-1, 2)\n",
    "    gt_joints = target_cont.reshape(-1, 2)\n",
    "    num_joints = gt_joints.shape[0]\n",
    "\n",
    "    j_points_gt = [gt_joints[i].tolist() for i in range(num_joints)]\n",
    "    j_points_pred = [pred_joints[i].tolist() for i in range(min(num_joints, pred_joints.shape[0]))]\n",
    "    couplerCurveIndex = num_joints - 1  # last joint as coupler\n",
    "\n",
    "    # --- ORIGINAL MECHANISM SIMULATION ---\n",
    "    exampleData = {\n",
    "        \"params\": j_points_gt,\n",
    "        \"type\": mech_type,\n",
    "        \"speedScale\": speedscale,\n",
    "        \"steps\": steps,\n",
    "        \"relativeTolerance\": 0.1,\n",
    "    }\n",
    "\n",
    "    if \"Type\" in mech_type:\n",
    "        API_ENDPOINT = f\"http://localhost:4000/simulation-8bar\"\n",
    "    else:\n",
    "        API_ENDPOINT = f\"http://localhost:4000/simulation\"\n",
    "\n",
    "    try:\n",
    "        if \"Type\" in mech_type:\n",
    "            exampleData = [exampleData]\n",
    "            temp = requests.post(url=API_ENDPOINT, headers=HEADERS, data=json.dumps(exampleData)).json()\n",
    "        else:\n",
    "            temp = requests.post(url=API_ENDPOINT, headers=HEADERS, data=json.dumps([exampleData])).json()\n",
    "\n",
    "        time.sleep(0.05)\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "    if temp[0][\"poses\"] is None:\n",
    "        continue\n",
    "\n",
    "    print(\"Known type: \", mech_type)\n",
    "\n",
    "    P = np.array(temp[0][\"poses\"])\n",
    "    if P.shape[0] < minsteps:\n",
    "        continue\n",
    "\n",
    "    original_x, original_y = P[:, couplerCurveIndex, 0], P[:, couplerCurveIndex, 1]\n",
    "    original_mean_x, original_mean_y = np.mean(original_x), np.mean(original_y)\n",
    "    original_denom = np.sqrt(np.var(original_x) + np.var(original_y))\n",
    "    original_phi = -get_pca_inclination(original_x, original_y)\n",
    "\n",
    "    # --- PREDICTED MECHANISM SIMULATION ---\n",
    "    if \"Type\" in mech_type:\n",
    "        API_ENDPOINT = f\"http://localhost:4000/simulation-8bar\"\n",
    "    else:\n",
    "        API_ENDPOINT = f\"http://localhost:4000/simulation\"\n",
    "    \n",
    "    exampleData[\"params\"] = j_points_pred\n",
    "    try:\n",
    "        if \"Type\" in mech_type:\n",
    "            exampleData = [exampleData]\n",
    "            temp = requests.post(url=API_ENDPOINT, headers=HEADERS, data=json.dumps(exampleData)).json()\n",
    "        else:\n",
    "            temp = requests.post(url=API_ENDPOINT, headers=HEADERS, data=json.dumps([exampleData])).json()\n",
    "\n",
    "        time.sleep(0.05)\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "    if temp[0][\"poses\"] is None:\n",
    "        continue\n",
    "\n",
    "    P = np.array(temp[0][\"poses\"])\n",
    "    if P.shape[0] < minsteps:\n",
    "        continue\n",
    "\n",
    "    generated_x, generated_y = P[:, couplerCurveIndex, 0], P[:, couplerCurveIndex, 1]\n",
    "    if np.isnan(generated_x).any() or np.isinf(generated_x).any() or len(generated_x) < 30:\n",
    "        continue\n",
    "\n",
    "    # --- ALIGN CURVES ---\n",
    "    generated_phi = -get_pca_inclination(generated_x, generated_y)\n",
    "    rotation = generated_phi - original_phi\n",
    "    generated_x, generated_y = rotate_curve(generated_x, generated_y, rotation)\n",
    "\n",
    "    generated_denom = np.sqrt(np.var(generated_x) + np.var(generated_y))\n",
    "    scale_factor = original_denom / generated_denom\n",
    "    generated_x, generated_y = np.multiply(generated_x, scale_factor), np.multiply(generated_y, scale_factor)\n",
    "\n",
    "    generated_mean_x, generated_mean_y = np.mean(generated_x), np.mean(generated_y)\n",
    "    translation_x, translation_y = generated_mean_x - original_mean_x, generated_mean_y - original_mean_y\n",
    "    generated_x, generated_y = np.subtract(generated_x, translation_x), np.subtract(generated_y, translation_y)\n",
    "\n",
    "    # --- PLOT BOTH CURVES ---\n",
    "    plt.plot(original_x, original_y, \"r\", label=\"original\")\n",
    "    # plt.plot(generated_x, generated_y, \"g\", label=\"predicted\")\n",
    "    plt.title(f\"Mechanism: {mech_type}\")\n",
    "    plt.axis(\"equal\")\n",
    "    plt.legend()\n",
    "\n",
    "    out_dir = f\"results/{idx}\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    plt.savefig(f\"{out_dir}/{idx}_{mech_type}_batch_pred.jpg\")\n",
    "    plt.clf()\n",
    "\n",
    "print(f\"Finished in {time.time() - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a679914-9897-4de2-aba8-6538ab91cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Started')\n",
    "# start_time = time.time()\n",
    "\n",
    "# for num, (images, joints, labels) in enumerate(data_loader):\n",
    "    \n",
    "#     if num == 1:\n",
    "#         break\n",
    "    \n",
    "#     for num_1, (image, joint, label) in enumerate(zip(images, joints, labels)):\n",
    "        \n",
    "#         if num_1 == 20:\n",
    "#             break\n",
    "            \n",
    "#         with torch.no_grad():\n",
    "#             image = image.repeat(batch_size, 1).to(device)\n",
    "\n",
    "#             indices = torch.arange(batch_size).unsqueeze(1)\n",
    "#             indices = indices[torch.randperm(batch_size)]\n",
    "#             random_labels = indices % 3\n",
    "#             random_labels = random_labels.to(dtype=torch.float32)\n",
    "#             # random_labels = torch.ones(batch_size, 1) * label\n",
    "#             random_labels = random_labels.to(device)\n",
    "            \n",
    "#             labels_encoded = model.label_encode(random_labels)\n",
    "#             # images_encoded = model.image_encode(image)\n",
    "            \n",
    "#             conditions = model.condition_cross_attention(labels_encoded, image)\n",
    "                                \n",
    "#             z = torch.randn([batch_size, attention_dim]).to(device)\n",
    "#             output = model.decoder_cross_attention(z, conditions)\n",
    "\n",
    "#             for decoder_self_attention in model.decoder_self_attentions:\n",
    "#                 output = decoder_self_attention(output)\n",
    "\n",
    "#             pred_joints = model.joint_predictor(output)\n",
    "    \n",
    "#         pred_joints = pred_joints.cpu().detach().numpy()\n",
    "#         random_labels = random_labels.cpu().detach().numpy()\n",
    "#         joint = joint.cpu().detach().numpy()\n",
    "#         label = label.numpy()\n",
    "        \n",
    "#         pred_joints = pred_joints[:100]\n",
    "#         random_labels = random_labels[:100]\n",
    "        \n",
    "#         for num_2, (pred_joint, random_label) in enumerate(zip(pred_joints, random_labels)):  \n",
    "            \n",
    "#             j_0, j_1, j_2, j_3, j_4 = [0.0, 0.0], [float(joint[0]), float(joint[1])], [float(joint[2]), float(joint[3])], \\\n",
    "#                           [float(joint[4]), float(joint[5])], [float(joint[6]), float(joint[7])]\n",
    "            \n",
    "#             couplerCurveIndex = 4\n",
    "#             posInit = [j_0, j_1, j_3, j_2, j_4] \n",
    "            \n",
    "#             if label[0] == 0:\n",
    "#                 mech_type = \"RRRR\"\n",
    "            \n",
    "#             elif label[0] == 1:\n",
    "#                 mech_type = \"RRRP\"\n",
    "                \n",
    "#             elif label[0] == 2:\n",
    "#                 mech_type = \"RRPR2\"              \n",
    "#                 posInit = [j_0, j_1, j_2, j_3, j_4]     \n",
    "                                        \n",
    "#             exampleData = {\n",
    "#                 'params': posInit, \n",
    "#                 'type': mech_type,\n",
    "#                 'speedScale': speedscale, \n",
    "#                 'steps': steps,\n",
    "#                 'relativeTolerance':0.1\n",
    "#             }\n",
    "\n",
    "#             try:\n",
    "#                 temp = requests.post(url = API_ENDPOINT, headers=HEADERS, data = json.dumps(exampleData)).json()\n",
    "#                 time.sleep(0.05)\n",
    "\n",
    "#             except ValueError as v:\n",
    "#                 for i in range(3):\n",
    "#                     time.sleep(2)\n",
    "#                     try:\n",
    "#                         temp = requests.post(url = API_ENDPOINT, headers=HEADERS, data = json.dumps(exampleData)).json()\n",
    "#                         break\n",
    "#                     except ValueError as v2:\n",
    "#                         plt.clf()\n",
    "#                         print('wtf')\n",
    "            \n",
    "#             if temp is None:\n",
    "#                 plt.clf()\n",
    "#                 continue\n",
    "                \n",
    "#             P = np.array(temp['poses'])\n",
    "            \n",
    "#             original_x, original_y = P[:, couplerCurveIndex, 0], P[:, couplerCurveIndex, 1]\n",
    "            \n",
    "#             original_mean_x, original_mean_y = np.mean(original_x), np.mean(original_y)\n",
    "#             original_denom = np.sqrt(np.var(original_x, axis=0, keepdims=True) + np.var(original_y, axis=0, keepdims=True))\n",
    "#             original_phi = -get_pca_inclination(original_x, original_y)\n",
    "            \n",
    "#             if P.shape[0] >= minsteps:\n",
    "#                 plt.plot(original_x, original_y, 'r', label='original')\n",
    "               \n",
    "#                 j_0, j_1, j_2, j_3, j_4 = [0.0, 0.0], [float(pred_joint[0]), float(pred_joint[1])], [float(pred_joint[2]), float(pred_joint[3])], \\\n",
    "#                                           [float(pred_joint[4]), float(pred_joint[5])], [float(pred_joint[6]), float(pred_joint[7])]\n",
    "                \n",
    "#                 posInit = [j_0, j_1, j_3, j_2, j_4] \n",
    "#                 couplerCurveIndex = 4\n",
    "                                             \n",
    "#                 if random_label[0] == 0.0:\n",
    "#                     mech_type = \"RRRR\"\n",
    "\n",
    "#                 elif random_label[0] == 1.0:\n",
    "#                     mech_type = \"RRRP\"\n",
    "                \n",
    "#                 elif random_label[0] == 2.0:\n",
    "#                     mech_type = \"RRPR2\"\n",
    "#                     posInit = [j_0, j_1, j_2, j_3, j_4]     \n",
    "                                \n",
    "#             exampleData = {\n",
    "#                 'params': posInit, \n",
    "#                 'type': mech_type,\n",
    "#                 'speedScale': speedscale, \n",
    "#                 'steps': steps,\n",
    "#                 'relativeTolerance':0.1\n",
    "#             }\n",
    "\n",
    "#             try:\n",
    "#                 temp = requests.post(url = API_ENDPOINT, headers=HEADERS, data = json.dumps(exampleData)).json()\n",
    "#                 time.sleep(0.05)\n",
    "\n",
    "#             except ValueError as v:\n",
    "#                 for i in range(3):\n",
    "#                     time.sleep(2)\n",
    "#                     try:\n",
    "#                         temp = requests.post(url = API_ENDPOINT, headers=HEADERS, data = json.dumps(exampleData)).json()\n",
    "#                         break\n",
    "#                     except ValueError as v2:\n",
    "#                         plt.clf()\n",
    "#                         print('wtf')\n",
    "            \n",
    "#             if temp is None:\n",
    "#                 plt.clf()\n",
    "#                 continue\n",
    "                \n",
    "#             P = np.array(temp['poses'])\n",
    "            \n",
    "#             generated_x, generated_y = P[:, couplerCurveIndex, 0], P[:, couplerCurveIndex, 1]\n",
    "                    \n",
    "#             if np.isnan(generated_x).any() or np.isinf(generated_x).any() or len(generated_x) < 30:\n",
    "#                 plt.clf()\n",
    "#                 continue\n",
    "            \n",
    "#             # Rotating\n",
    "#             generated_phi = -get_pca_inclination(generated_x, generated_y)\n",
    "#             rotation = generated_phi - original_phi\n",
    "#             generated_x, generated_y = rotate_curve(generated_x, generated_y, rotation)\n",
    "            \n",
    "#             j_0 = rotate_curve(j_0[0], j_0[1], rotation)\n",
    "#             j_1 = rotate_curve(j_1[0], j_1[1], rotation)\n",
    "#             j_2 = rotate_curve(j_2[0], j_2[1], rotation)\n",
    "#             j_3 = rotate_curve(j_3[0], j_3[1], rotation)\n",
    "#             j_4 = rotate_curve(j_4[0], j_4[1], rotation)\n",
    "                        \n",
    "#             # Scaling\n",
    "#             generated_denom = np.sqrt(np.var(generated_x, axis=0, keepdims=True) + np.var(generated_y, axis=0, keepdims=True))\n",
    "#             scale_factor = original_denom / generated_denom\n",
    "#             generated_x, generated_y = np.multiply(generated_x, scale_factor), np.multiply(generated_y, scale_factor)\n",
    "            \n",
    "#             j_0 = [np.multiply(j_0[0], scale_factor), np.multiply(j_0[1], scale_factor)]\n",
    "#             j_1 = [np.multiply(j_1[0], scale_factor), np.multiply(j_1[1], scale_factor)]\n",
    "#             j_2 = [np.multiply(j_2[0], scale_factor), np.multiply(j_2[1], scale_factor)]\n",
    "#             j_3 = [np.multiply(j_3[0], scale_factor), np.multiply(j_3[1], scale_factor)]\n",
    "#             j_4 = [np.multiply(j_4[0], scale_factor), np.multiply(j_4[1], scale_factor)]\n",
    "            \n",
    "#             # Translating\n",
    "#             generated_mean_x, generated_mean_y = np.mean(generated_x), np.mean(generated_y)\n",
    "#             translation_x, translation_y = generated_mean_x - original_mean_x, generated_mean_y - original_mean_y\n",
    "#             generated_x, generated_y = np.subtract(generated_x, translation_x), np.subtract(generated_y, translation_y)\n",
    "            \n",
    "#             j_0 = [np.subtract(j_0[0], translation_x), np.subtract(j_0[1], translation_y)]\n",
    "#             j_1 = [np.subtract(j_1[0], translation_x), np.subtract(j_1[1], translation_y)]\n",
    "#             j_2 = [np.subtract(j_2[0], translation_x), np.subtract(j_2[1], translation_y)]\n",
    "#             j_3 = [np.subtract(j_3[0], translation_x), np.subtract(j_3[1], translation_y)]\n",
    "#             j_4 = [np.subtract(j_4[0], translation_x), np.subtract(j_4[1], translation_y)]\n",
    "            \n",
    "#             if P.shape[0] >= minsteps:\n",
    "#                 plt.plot(generated_x, generated_y, 'g', label='predicted')\n",
    "                \n",
    "#                 if random_label[0] == 0.0:\n",
    "#                     plt.plot(j_0[0], j_0[1], marker=\"x\", markersize=10, markeredgecolor='red',\n",
    "#                          markerfacecolor='red')\n",
    "#                     plt.plot(j_3[0], j_3[1], marker=\"x\", markersize=10, markeredgecolor='green',\n",
    "#                              markerfacecolor='green')\n",
    "\n",
    "#                     x = [j_1[0], j_4[0], j_2[0], j_1[0]]\n",
    "#                     y = [j_1[1], j_4[1], j_2[1], j_1[1]]\n",
    "#                     plt.fill(x, y, color='pink')\n",
    "                    \n",
    "#                     plt.plot([j_0[0], j_1[0]], [j_0[1], j_1[1]], color='green')\n",
    "#                     plt.plot([j_2[0], j_3[0]], [j_2[1], j_3[1]], color='green')\n",
    "\n",
    "#                 elif random_label[0] == 1.0:\n",
    "#                     plt.plot(j_0[0], j_0[1], marker=\"x\", markersize=10, markeredgecolor='red',\n",
    "#                              markerfacecolor='red')\n",
    "#                     plt.plot(j_2[0], j_2[1], marker=\"x\", markersize=10, markeredgecolor='green',\n",
    "#                              markerfacecolor='green')\n",
    "#                     plt.plot(j_3[0], j_3[1], marker=\"x\", markersize=10, markeredgecolor='green',\n",
    "#                              markerfacecolor='green')\n",
    "    \n",
    "#                     j_5 = [(j_2[0] + j_3[0]) / 2 , (j_2[1] + j_3[1]) / 2]\n",
    "                    \n",
    "#                     x = [j_1[0], j_4[0], j_5[0], j_1[0]]\n",
    "#                     y = [j_1[1], j_4[1], j_5[1], j_1[1]]\n",
    "#                     plt.fill(x, y, color='pink')\n",
    "                    \n",
    "#                     plt.plot([j_0[0], j_1[0]], [j_0[1], j_1[1]], color='green')\n",
    "#                     plt.plot([j_2[0], j_3[0]], [j_2[1], j_3[1]], color='green')\n",
    "\n",
    "#                 elif random_label[0] == 2.0:\n",
    "#                     plt.plot(j_0[0], j_0[1], marker=\"x\", markersize=10, markeredgecolor='red',\n",
    "#                              markerfacecolor='red')\n",
    "#                     plt.plot(j_2[0], j_2[1], marker=\"x\", markersize=10, markeredgecolor='green',\n",
    "#                              markerfacecolor='green')\n",
    "\n",
    "#                     x = [j_1[0], j_4[0], j_3[0], j_1[0]]\n",
    "#                     y = [j_1[1], j_4[1], j_3[1], j_1[1]]\n",
    "#                     plt.fill(x, y, color='pink')\n",
    "\n",
    "#                     plt.plot([j_0[0], j_1[0]], [j_0[1], j_1[1]], color='green')\n",
    "#                     plt.plot([j_2[0], j_3[0]], [j_2[1], j_3[1]], color='green')\n",
    "                                                        \n",
    "#             if not os.path.exists('results'):\n",
    "#                 os.makedirs('results')\n",
    "#             if not os.path.exists('results/{} {}'.format(num_1, label[0])):\n",
    "#                 os.makedirs('results/{} {}'.format(num_1, label[0]))\n",
    "            \n",
    "#             plt.axis('equal')\n",
    "#             plt.legend()\n",
    "#             plt.savefig('results/{} {}/{} {}.jpg'.format(num_1, label[0], num_2, random_label[0]))\n",
    "#             plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0227c5-47f5-4869-8a9c-9d3a5e358398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !rm results.zip\n",
    "# !zip -r results.zip results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ced518-4ef4-465d-8de6-2c98f8834dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
