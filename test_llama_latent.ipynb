{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6746bb70-eb1f-473e-bc2b-97abcf5067f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anurizada/anaconda3/envs/transformer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-12-04 20:03:58.681232: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764896638.693482 3821602 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764896638.697378 3821602 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764896638.708419 3821602 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764896638.708429 3821602 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764896638.708431 3821602 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764896638.708433 3821602 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-12-04 20:03:58.711610: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from llama_latent_model import LatentLLaMA_SingleToken\n",
    "from dataset import BarLinkageDataset \n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from dataset_generation.curve_plot import get_pca_inclination, rotate_curve\n",
    "import scipy.spatial.distance as sciDist\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0354fc90-9448-4531-ad0b-f95058e8fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headless simulator version\n",
    "index = 0 # local server index \n",
    "API_ENDPOINT = f\"http://localhost:4000/simulation\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "speedscale = 1\n",
    "steps = 360\n",
    "minsteps = int(steps*20/360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e8ae72c-963c-458f-a536-c6737e88084f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded VAE latents: (548630, 50)\n",
      "âœ… Loaded dataset from /home/anurizada/Documents/processed_dataset_17 with 548630 samples\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./weights/CE_GAUS/LATENT_LLAMA_d768_h8_n6_bs512_lr0.0005_best.pth\"\n",
    "data_dir = \"/home/anurizada/Documents/processed_dataset_17\"\n",
    "batch_size = 1\n",
    "\n",
    "dataset = BarLinkageDataset(data_dir=data_dir)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4913484-58cd-4236-bc77-e3cf855f884b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ Initialized LatentLLaMA_SingleToken (one-token latent conditioning)\n",
      "\n",
      "ðŸ§® Model Parameter Summary\n",
      "Total parameters:     57,762,252  (57.76 M)\n",
      "Trainable parameters: 57,605,580  (57.61 M)\n",
      "Frozen parameters:    156,672  (0.16 M)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57762252, 57605580, 156672)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model_config = checkpoint['model_config']\n",
    "\n",
    "# Initialize model\n",
    "model = LatentLLaMA_SingleToken(\n",
    "    tgt_seq_len=model_config['tgt_seq_len'],\n",
    "    d_model=model_config['d_model'],\n",
    "    h=model_config['h'],\n",
    "    N=model_config['N'],\n",
    "    num_labels=model_config['num_labels'],\n",
    "    vocab_size=model_config['vocab_size'],\n",
    "    latent_dim=model_config['latent_dim']).to(device)\n",
    "\n",
    "# Load weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# ---------------------------\n",
    "# Count parameters\n",
    "# ---------------------------\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    non_trainable_params = total_params - trainable_params\n",
    "\n",
    "    print(\"\\nðŸ§® Model Parameter Summary\")\n",
    "    print(f\"Total parameters:     {total_params:,}  ({total_params/1e6:.2f} M)\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}  ({trainable_params/1e6:.2f} M)\")\n",
    "    print(f\"Frozen parameters:    {non_trainable_params:,}  ({non_trainable_params/1e6:.2f} M)\")\n",
    "    return total_params, trainable_params, non_trainable_params\n",
    "\n",
    "# Run the counter\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1ef477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded VAE latents: (548630, 50)\n",
      "âœ… Loaded dataset from /home/anurizada/Documents/processed_dataset_17 with 548630 samples\n",
      "ðŸ”¥ Initialized LatentLLaMA_SingleToken (one-token latent conditioning)\n",
      "Starting conditional coupler curve generation (latent-based, greedy decoding)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# =========================================================\n",
    "# SIMULATOR CONFIG\n",
    "# =========================================================\n",
    "API_ENDPOINT = \"http://localhost:4000/simulation\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "speedscale = 1\n",
    "steps = 360\n",
    "minsteps = int(steps * 20 / 360)\n",
    "\n",
    "# =========================================================\n",
    "# MODEL / DATASET LOADING\n",
    "# =========================================================\n",
    "checkpoint_path = \"./weights/CE_GAUS/LATENT_LLAMA_d768_h8_n6_bs512_lr0.0005_best.pth\"\n",
    "data_dir = \"/home/anurizada/Documents/processed_dataset_17\"\n",
    "batch_size = 1\n",
    "\n",
    "dataset = BarLinkageDataset(data_dir=data_dir)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model_config = checkpoint[\"model_config\"]\n",
    "\n",
    "model = LatentLLaMA_SingleToken(\n",
    "    tgt_seq_len=model_config[\"tgt_seq_len\"],\n",
    "    d_model=model_config[\"d_model\"],\n",
    "    h=model_config[\"h\"],\n",
    "    N=model_config[\"N\"],\n",
    "    num_labels=model_config[\"num_labels\"],\n",
    "    vocab_size=model_config[\"vocab_size\"],\n",
    "    latent_dim=model_config[\"latent_dim\"]\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "# =========================================================\n",
    "# CONFIG\n",
    "# =========================================================\n",
    "MAX_SAMPLES = 100\n",
    "SOS_TOKEN, EOS_TOKEN, PAD_TOKEN = 0, 1, 2\n",
    "NUM_SPECIAL_TOKENS = 3\n",
    "NUM_MECH_TYPES = 17\n",
    "BIN_OFFSET = NUM_SPECIAL_TOKENS\n",
    "NUM_BINS = 201\n",
    "LATENT_DIM = 50   # must match training\n",
    "\n",
    "label_mapping_path = \"/home/anurizada/Documents/processed_dataset_17/label_mapping.json\"\n",
    "coupler_mapping_path = \"/home/anurizada/Documents/transformer/BSIdict.json\"\n",
    "\n",
    "with open(label_mapping_path, \"r\") as f:\n",
    "    label_mapping = json.load(f)\n",
    "index_to_label = label_mapping[\"index_to_label\"]\n",
    "\n",
    "with open(coupler_mapping_path, \"r\") as f:\n",
    "    coupler_mapping = json.load(f)\n",
    "\n",
    "\n",
    "def coupler_index_for(mech_type: str) -> int:\n",
    "    \"\"\"Return coupler curve index from BSIdict.json.\"\"\"\n",
    "    if mech_type in coupler_mapping and \"c\" in coupler_mapping[mech_type]:\n",
    "        cvec = coupler_mapping[mech_type][\"c\"]\n",
    "        if isinstance(cvec, list) and 1 in cvec:\n",
    "            return cvec.index(1)\n",
    "    return -1\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Helper: safe + short names for filesystem paths\n",
    "# ---------------------------------------------------------\n",
    "def safe_name(name: str, max_len: int = 30) -> str:\n",
    "    chars = []\n",
    "    for c in name:\n",
    "        if c.isalnum():\n",
    "            chars.append(c)\n",
    "        else:\n",
    "            chars.append(\"_\")\n",
    "    sanitized = \"\".join(chars)\n",
    "    return sanitized[:max_len] or \"unk\"\n",
    "\n",
    "\n",
    "def temp_to_str(t: float) -> str:\n",
    "    s = f\"{t:.2f}\".rstrip(\"0\").rstrip(\".\")\n",
    "    s = s.replace(\".\", \"p\").replace(\"-\", \"m\")\n",
    "    return s or \"0\"\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# CoordinateBinner (matches training)\n",
    "# =========================================================\n",
    "class CoordinateBinner:\n",
    "    def __init__(self, kappa=1.0, num_bins=200):\n",
    "        self.kappa = kappa\n",
    "        self.num_bins = num_bins\n",
    "        self.bin_edges = np.linspace(-kappa, kappa, num_bins + 1)\n",
    "        self.bin_centers = (self.bin_edges[:-1] + self.bin_edges[1:]) / 2\n",
    "\n",
    "    def bin_to_value_torch(self, idx):\n",
    "        idx = torch.clamp(idx, 0, self.num_bins - 1)\n",
    "        centers = torch.tensor(self.bin_centers, device=idx.device, dtype=torch.float32)\n",
    "        return centers[idx]\n",
    "\n",
    "\n",
    "binner = CoordinateBinner(kappa=1.0, num_bins=NUM_BINS - 1)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Causal mask\n",
    "# =========================================================\n",
    "def build_causal_mask(seq_len, device):\n",
    "    m = torch.tril(torch.ones(seq_len, seq_len, dtype=torch.bool, device=device))\n",
    "    return m.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Joint connections from B-matrix\n",
    "# =========================================================\n",
    "def get_joint_connections(mech_name: str):\n",
    "    \"\"\"\n",
    "    Given mechanism name (e.g. 'RRRR'), return a list of joint index pairs (a,b)\n",
    "    indicating which joints should be connected by links.\n",
    "    Uses the B matrix from coupler_mapping[mech_name][\"B\"].\n",
    "    \"\"\"\n",
    "    if mech_name not in coupler_mapping:\n",
    "        return []\n",
    "\n",
    "    mech_entry = coupler_mapping[mech_name]\n",
    "    if \"B\" not in mech_entry:\n",
    "        return []\n",
    "\n",
    "    B = mech_entry[\"B\"]\n",
    "    connections = []\n",
    "\n",
    "    for row in B:\n",
    "        joints = [j for j, val in enumerate(row) if val == 1]\n",
    "        if len(joints) >= 2:\n",
    "            # Connect all pairs of joints in this link\n",
    "            for a in range(len(joints)):\n",
    "                for b in range(a + 1, len(joints)):\n",
    "                    connections.append((joints[a], joints[b]))\n",
    "\n",
    "    return connections\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# AUTOREGRESSIVE LATENT DECODING â€” GREEDY (temp=0, top_k=None)\n",
    "# =========================================================\n",
    "def predict_autoregressive_latent(\n",
    "    model, latent, mech_idx, max_seq_len, device,\n",
    "    eos_token=EOS_TOKEN, sos_token=SOS_TOKEN\n",
    "):\n",
    "    \"\"\"\n",
    "    Greedy decoding:\n",
    "      - No temperature scaling\n",
    "      - No top-k\n",
    "      - At each step use argmax over logits\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    if latent.dim() == 1:\n",
    "        latent = latent.unsqueeze(0)\n",
    "\n",
    "    latent = latent.to(device)\n",
    "    mech_labels = torch.tensor([mech_idx], dtype=torch.long, device=device)\n",
    "\n",
    "    decoder_input = torch.tensor([[sos_token]], dtype=torch.long, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_seq_len):\n",
    "            mask = build_causal_mask(decoder_input.size(1), device)\n",
    "            logits = model(decoder_input, mask, latent, mech_labels)\n",
    "            # Take last-step logits\n",
    "            last_logits = logits[:, -1, :]\n",
    "            # Greedy choice (argmax)\n",
    "            next_token = torch.argmax(last_logits, dim=-1, keepdim=True)\n",
    "\n",
    "            token = int(next_token.item())\n",
    "            decoder_input = torch.cat([decoder_input, next_token], dim=1)\n",
    "            if token == eos_token:\n",
    "                break\n",
    "\n",
    "    return decoder_input.squeeze(0).cpu().numpy()\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# MAIN\n",
    "# =========================================================\n",
    "tgt_seq_len = model_config[\"tgt_seq_len\"]\n",
    "\n",
    "print(\"Starting conditional coupler curve generation (latent-based, greedy decoding)...\")\n",
    "os.makedirs(\"results_coupler_latent\", exist_ok=True)\n",
    "\n",
    "for i, batch in enumerate(tqdm(dataloader, total=min(MAX_SAMPLES, len(dataset)), desc=\"Simulating\")):\n",
    "    if i >= MAX_SAMPLES:\n",
    "        break\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # Latent\n",
    "    # ----------------------------------------------------\n",
    "    latents = batch[\"vae_mu\"].to(device).squeeze(-1)\n",
    "    latent = latents[0]\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # Ground truth mechanism info\n",
    "    # ----------------------------------------------------\n",
    "    gt_tokens = batch[\"labels_discrete\"][0].numpy()\n",
    "    gt_mech_idx = int(batch[\"encoded_labels\"][0].item())\n",
    "    gt_mech_name = index_to_label[str(gt_mech_idx)]\n",
    "    gt_mech_safe = safe_name(gt_mech_name)\n",
    "\n",
    "    sample_dir = f\"results_coupler_latent/sample_{i:03d}_{gt_mech_safe}\"\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # Save input image\n",
    "    # ----------------------------------------------------\n",
    "    if \"images\" in batch:\n",
    "        img_np = batch[\"images\"][0].detach().cpu().squeeze().numpy()\n",
    "        plt.imsave(os.path.join(sample_dir, \"input_image.png\"), img_np, cmap=\"gray\")\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # Decode ground truth joints\n",
    "    # ----------------------------------------------------\n",
    "    gt_coord_tokens = [t for t in gt_tokens if t >= BIN_OFFSET]\n",
    "    if len(gt_coord_tokens) < 4:\n",
    "        continue\n",
    "\n",
    "    gt_coords = binner.bin_to_value_torch(\n",
    "        torch.tensor(gt_coord_tokens, device=device) - BIN_OFFSET\n",
    "    ).cpu().numpy()\n",
    "\n",
    "    if gt_coords.size % 2:\n",
    "        gt_coords = gt_coords[:-1]\n",
    "\n",
    "    gt_points = gt_coords.reshape(-1, 2)\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # Simulate ground truth coupler motion\n",
    "    # ----------------------------------------------------\n",
    "    sim_req = {\n",
    "        \"params\": gt_points.tolist(),\n",
    "        \"type\": gt_mech_name,\n",
    "        \"speedScale\": speedscale,\n",
    "        \"steps\": steps,\n",
    "        \"relativeTolerance\": 0.1,\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.post(API_ENDPOINT, headers=HEADERS, data=json.dumps([sim_req])).json()\n",
    "        P = np.array(resp[0][\"poses\"]) if isinstance(resp, list) and \"poses\" in resp[0] else None\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    if P is None or P.shape[0] < minsteps:\n",
    "        continue\n",
    "\n",
    "    coup_idx = coupler_index_for(gt_mech_name)\n",
    "    if coup_idx < 0:\n",
    "        continue\n",
    "\n",
    "    original_x = P[:, coup_idx, 0]\n",
    "    original_y = P[:, coup_idx, 1]\n",
    "\n",
    "    # Normalization parameters (for aligning predicted coupler)\n",
    "    orig_phi = -get_pca_inclination(original_x, original_y)\n",
    "    orig_denom = np.sqrt(np.var(original_x) + np.var(original_y)) + 1e-8\n",
    "    ox_mean, oy_mean = np.mean(original_x), np.mean(original_y)\n",
    "\n",
    "    # Store predictions (per mechanism + \"temperature tag\")\n",
    "    all_predicted_points = {}\n",
    "\n",
    "    # ============================================================\n",
    "    # Loop: all mechanisms â€” here we only do greedy decoding\n",
    "    # (we still keep a 'temperatures' list for filenames; but\n",
    "    #  decoding itself is deterministic and ignores its value)\n",
    "    # ============================================================\n",
    "    temperatures = [0.0]  # can add more values if you only use as tags\n",
    "\n",
    "    for mech_idx in range(NUM_MECH_TYPES):\n",
    "        mech_name = index_to_label[str(mech_idx)]\n",
    "        mech_safe = safe_name(mech_name)\n",
    "\n",
    "        for temp in temperatures:\n",
    "            temp_str = temp_to_str(temp)\n",
    "\n",
    "            # ----------------------------------------------------\n",
    "            # Predict joints (GREEDY)\n",
    "            # ----------------------------------------------------\n",
    "            pred_tokens = predict_autoregressive_latent(\n",
    "                model, latent, mech_idx, tgt_seq_len, device\n",
    "            )\n",
    "\n",
    "            coord_tokens = [t for t in pred_tokens if t >= BIN_OFFSET]\n",
    "            if len(coord_tokens) < 4:\n",
    "                continue\n",
    "\n",
    "            coords_float = binner.bin_to_value_torch(\n",
    "                torch.tensor(coord_tokens, device=device) - BIN_OFFSET\n",
    "            ).cpu().numpy()\n",
    "\n",
    "            if coords_float.size % 2 == 1:\n",
    "                coords_float = coords_float[:-1]\n",
    "\n",
    "            pred_points = coords_float.reshape(-1, 2)\n",
    "            # IMPORTANT: store with real mech_name, not sanitized\n",
    "            all_predicted_points[(mech_name, temp_str)] = pred_points\n",
    "\n",
    "            # ----------------------------------------------------\n",
    "            # Simulate predicted mechanism\n",
    "            # ----------------------------------------------------\n",
    "            sim_req_pred = {\n",
    "                \"params\": pred_points.tolist(),\n",
    "                \"type\": mech_name,\n",
    "                \"speedScale\": speedscale,\n",
    "                \"steps\": steps,\n",
    "                \"relativeTolerance\": 0.1,\n",
    "            }\n",
    "            try:\n",
    "                resp_p = requests.post(API_ENDPOINT, headers=HEADERS, data=json.dumps([sim_req_pred])).json()\n",
    "                Pp = np.array(resp_p[0][\"poses\"]) if isinstance(resp_p, list) and \"poses\" in resp_p[0] else None\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            if Pp is None or Pp.shape[0] < minsteps:\n",
    "                continue\n",
    "\n",
    "            coup_idx_pred = coupler_index_for(mech_name)\n",
    "            if coup_idx_pred < 0:\n",
    "                continue\n",
    "\n",
    "            gen_x = Pp[:, coup_idx_pred, 0]\n",
    "            gen_y = Pp[:, coup_idx_pred, 1]\n",
    "\n",
    "            # ----------------------------------------------------\n",
    "            # Align predicted coupler to GT\n",
    "            # ----------------------------------------------------\n",
    "            gen_phi = -get_pca_inclination(gen_x, gen_y)\n",
    "            rotation = gen_phi - orig_phi\n",
    "            gen_x, gen_y = rotate_curve(gen_x, gen_y, rotation)\n",
    "\n",
    "            gen_denom = np.sqrt(np.var(gen_x) + np.var(gen_y)) + 1e-8\n",
    "            scale = orig_denom / gen_denom\n",
    "            gen_x *= scale\n",
    "            gen_y *= scale\n",
    "\n",
    "            gen_x -= (np.mean(gen_x) - ox_mean)\n",
    "            gen_y -= (np.mean(gen_y) - oy_mean)\n",
    "\n",
    "            # ----------------------------------------------------\n",
    "            # PLOT WITH JOINT NUMBERING + LINKS\n",
    "            # ----------------------------------------------------\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.plot(original_x, original_y, \"r-\", label=f\"GT ({gt_mech_name})\")\n",
    "            plt.plot(gen_x, gen_y, \"g--\", label=f\"Pred {mech_name} t={temp_str}\")\n",
    "\n",
    "            # GT joints (numbered)\n",
    "            plt.scatter(gt_points[:, 0], gt_points[:, 1], c=\"red\", s=50)\n",
    "            for j, (xj, yj) in enumerate(gt_points):\n",
    "                plt.text(xj + 0.003, yj + 0.003, f\"{j}\", fontsize=9, color=\"red\")\n",
    "\n",
    "            # Predicted joints (numbered)\n",
    "            for j, (xp, yp) in enumerate(pred_points):\n",
    "                plt.scatter(xp, yp, c=\"green\", s=50)\n",
    "                plt.text(xp + 0.003, yp + 0.003, f\"{j}\", fontsize=8, color=\"green\")\n",
    "\n",
    "            # CONNECT predicted joints according to B-matrix\n",
    "            connections = get_joint_connections(mech_name)\n",
    "            for a, b in connections:\n",
    "                if a < pred_points.shape[0] and b < pred_points.shape[0]:\n",
    "                    x1, y1 = pred_points[a]\n",
    "                    x2, y2 = pred_points[b]\n",
    "                    plt.plot([x1, x2], [y1, y2], \"g-\", linewidth=1)\n",
    "\n",
    "            plt.axis(\"equal\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "\n",
    "            save_path = os.path.join(sample_dir, f\"{mech_safe}_t{temp_str}.png\")\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "\n",
    "    # ============================================================\n",
    "    # FINAL: Combined joint scatter plot (numbered + links)\n",
    "    # ============================================================\n",
    "    if len(all_predicted_points) == 0:\n",
    "        continue\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    # GT numbered\n",
    "    plt.scatter(gt_points[:, 0], gt_points[:, 1], c=\"red\", s=90, edgecolor=\"black\")\n",
    "    for j, (x, y) in enumerate(gt_points):\n",
    "        plt.text(x + 0.005, y + 0.005, f\"{j}\", color=\"red\", fontsize=10)\n",
    "\n",
    "    max_joints = max(pts.shape[0] for pts in all_predicted_points.values())\n",
    "    cmap = plt.cm.get_cmap(\"tab10\", max_joints)\n",
    "\n",
    "    for (mech_name, temp_str), pts in all_predicted_points.items():\n",
    "        # Scatter joints with index-based colors\n",
    "        for j in range(pts.shape[0]):\n",
    "            color = cmap(j % max_joints)\n",
    "            xj, yj = pts[j]\n",
    "            plt.scatter(xj, yj, color=color, s=40)\n",
    "            plt.text(xj + 0.003, yj + 0.003, f\"{j}\", fontsize=8, color=color)\n",
    "\n",
    "        # Draw linkage connections for this mechanism\n",
    "        connections = get_joint_connections(mech_name)\n",
    "        for a, b in connections:\n",
    "            if a < pts.shape[0] and b < pts.shape[0]:\n",
    "                x1, y1 = pts[a]\n",
    "                x2, y2 = pts[b]\n",
    "                plt.plot([x1, x2], [y1, y2], \"-\", linewidth=1)\n",
    "\n",
    "    plt.axis(\"equal\")\n",
    "    plt.title(f\"Predicted Joints â€” Sample {i} â€” GT={gt_mech_name}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out_path = os.path.join(sample_dir, \"all_predicted_joints_colored.png\")\n",
    "    plt.savefig(out_path, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved: {out_path}\")\n",
    "\n",
    "print(\"DONE.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ad52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =========================================================\n",
    "# # CONFIG\n",
    "# # =========================================================\n",
    "# MAX_SAMPLES = 100\n",
    "# SOS_TOKEN, EOS_TOKEN, PAD_TOKEN = 0, 1, 2\n",
    "# NUM_SPECIAL_TOKENS = 3\n",
    "# NUM_MECH_TYPES = 17\n",
    "# BIN_OFFSET = NUM_SPECIAL_TOKENS\n",
    "# NUM_BINS = 201\n",
    "# LATENT_DIM = 50   # must match training\n",
    "\n",
    "# label_mapping_path = \"/home/anurizada/Documents/processed_dataset_17/label_mapping.json\"\n",
    "# coupler_mapping_path = \"/home/anurizada/Documents/transformer/BSIdict.json\"\n",
    "\n",
    "# with open(label_mapping_path, \"r\") as f:\n",
    "#     label_mapping = json.load(f)\n",
    "# index_to_label = label_mapping[\"index_to_label\"]\n",
    "\n",
    "# with open(coupler_mapping_path, \"r\") as f:\n",
    "#     coupler_mapping = json.load(f)\n",
    "\n",
    "\n",
    "# def coupler_index_for(mech_type: str) -> int:\n",
    "#     \"\"\"Return coupler curve index from BSIdict.json.\"\"\"\n",
    "#     if mech_type in coupler_mapping and \"c\" in coupler_mapping[mech_type]:\n",
    "#         cvec = coupler_mapping[mech_type][\"c\"]\n",
    "#         if isinstance(cvec, list) and 1 in cvec:\n",
    "#             return cvec.index(1)\n",
    "#     return -1\n",
    "\n",
    "\n",
    "# # ---------------------------------------------------------\n",
    "# # Helper: safe + short names for filesystem paths\n",
    "# # ---------------------------------------------------------\n",
    "# def safe_name(name: str, max_len: int = 30) -> str:\n",
    "#     chars = []\n",
    "#     for c in name:\n",
    "#         if c.isalnum():\n",
    "#             chars.append(c)\n",
    "#         else:\n",
    "#             chars.append(\"_\")\n",
    "#     sanitized = \"\".join(chars)\n",
    "#     return sanitized[:max_len] or \"unk\"\n",
    "\n",
    "\n",
    "# def temp_to_str(t: float) -> str:\n",
    "#     s = f\"{t:.2f}\".rstrip(\"0\").rstrip(\".\")\n",
    "#     s = s.replace(\".\", \"p\").replace(\"-\", \"m\")\n",
    "#     return s or \"0\"\n",
    "\n",
    "\n",
    "# # =========================================================\n",
    "# # CoordinateBinner (matches training)\n",
    "# # =========================================================\n",
    "# class CoordinateBinner:\n",
    "#     def __init__(self, kappa=1.0, num_bins=200):\n",
    "#         self.kappa = kappa\n",
    "#         self.num_bins = num_bins\n",
    "#         self.bin_edges = np.linspace(-kappa, kappa, num_bins + 1)\n",
    "#         self.bin_centers = (self.bin_edges[:-1] + self.bin_edges[1:]) / 2\n",
    "\n",
    "#     def bin_to_value_torch(self, idx):\n",
    "#         idx = torch.clamp(idx, 0, self.num_bins - 1)\n",
    "#         centers = torch.tensor(self.bin_centers, device=idx.device, dtype=torch.float32)\n",
    "#         return centers[idx]\n",
    "\n",
    "\n",
    "# binner = CoordinateBinner(kappa=1.0, num_bins=NUM_BINS - 1)\n",
    "\n",
    "\n",
    "# # =========================================================\n",
    "# # Causal mask\n",
    "# # =========================================================\n",
    "# def build_causal_mask(seq_len, device):\n",
    "#     m = torch.tril(torch.ones(seq_len, seq_len, dtype=torch.bool, device=device))\n",
    "#     return m.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "\n",
    "# # =========================================================\n",
    "# # AUTOREGRESSIVE LATENT DECODING\n",
    "# # =========================================================\n",
    "# def predict_autoregressive_latent(\n",
    "#     model, latent, mech_idx, max_seq_len, device,\n",
    "#     temperature=1.0, top_k=None, eos_token=EOS_TOKEN, sos_token=SOS_TOKEN\n",
    "# ):\n",
    "#     model.eval()\n",
    "\n",
    "#     if latent.dim() == 1:\n",
    "#         latent = latent.unsqueeze(0)\n",
    "\n",
    "#     latent = latent.to(device)\n",
    "#     mech_labels = torch.tensor([mech_idx], dtype=torch.long, device=device)\n",
    "\n",
    "#     decoder_input = torch.tensor([[sos_token]], dtype=torch.long, device=device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for _ in range(max_seq_len):\n",
    "#             mask = build_causal_mask(decoder_input.size(1), device)\n",
    "#             logits = model(decoder_input, mask, latent, mech_labels)\n",
    "#             logits = logits[:, -1, :] / max(temperature, 1e-6)\n",
    "#             probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "#             if top_k is not None:\n",
    "#                 k = min(top_k, probs.size(-1))\n",
    "#                 topk_probs, topk_idx = torch.topk(probs, k)\n",
    "#                 next_token = topk_idx.gather(-1, torch.multinomial(topk_probs, 1))\n",
    "#             elif temperature == 0:\n",
    "#                 next_token = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "#             else:\n",
    "#                 next_token = torch.multinomial(probs, 1)\n",
    "\n",
    "#             token = int(next_token.item())\n",
    "#             decoder_input = torch.cat([decoder_input, next_token], dim=1)\n",
    "#             if token == eos_token:\n",
    "#                 break\n",
    "\n",
    "#     return decoder_input.squeeze(0).cpu().numpy()\n",
    "\n",
    "\n",
    "# # =========================================================\n",
    "# # MAIN\n",
    "# # =========================================================\n",
    "# tgt_seq_len = model_config[\"tgt_seq_len\"]\n",
    "\n",
    "# print(\"Starting conditional coupler curve generation (latent-based)...\")\n",
    "# os.makedirs(\"results_coupler_latent\", exist_ok=True)\n",
    "\n",
    "# for i, batch in enumerate(tqdm(dataloader, total=min(MAX_SAMPLES, len(dataset)), desc=\"Simulating\")):\n",
    "#     if i >= MAX_SAMPLES:\n",
    "#         break\n",
    "\n",
    "#     # ----------------------------------------------------\n",
    "#     # Latent\n",
    "#     # ----------------------------------------------------\n",
    "#     latents = batch[\"vae_mu\"].to(device).squeeze(-1)\n",
    "#     latent = latents[0]\n",
    "\n",
    "#     # ----------------------------------------------------\n",
    "#     # Ground truth mechanism info\n",
    "#     # ----------------------------------------------------\n",
    "#     gt_tokens = batch[\"labels_discrete\"][0].numpy()\n",
    "#     gt_mech_idx = int(batch[\"encoded_labels\"][0].item())\n",
    "#     gt_mech_name = index_to_label[str(gt_mech_idx)]\n",
    "#     gt_mech_safe = safe_name(gt_mech_name)\n",
    "\n",
    "#     sample_dir = f\"results_coupler_latent/sample_{i:03d}_{gt_mech_safe}\"\n",
    "#     os.makedirs(sample_dir, exist_ok=True)\n",
    "\n",
    "#     # ----------------------------------------------------\n",
    "#     # Save input image\n",
    "#     # ----------------------------------------------------\n",
    "#     if \"images\" in batch:\n",
    "#         img_np = batch[\"images\"][0].detach().cpu().squeeze().numpy()\n",
    "#         plt.imsave(os.path.join(sample_dir, \"input_image.png\"), img_np, cmap=\"gray\")\n",
    "\n",
    "#     # ----------------------------------------------------\n",
    "#     # Decode ground truth joints\n",
    "#     # ----------------------------------------------------\n",
    "#     gt_coord_tokens = [t for t in gt_tokens if t >= BIN_OFFSET]\n",
    "#     if len(gt_coord_tokens) < 4:\n",
    "#         continue\n",
    "\n",
    "#     gt_coords = binner.bin_to_value_torch(\n",
    "#         torch.tensor(gt_coord_tokens, device=device) - BIN_OFFSET\n",
    "#     ).cpu().numpy()\n",
    "\n",
    "#     if gt_coords.size % 2:\n",
    "#         gt_coords = gt_coords[:-1]\n",
    "\n",
    "#     gt_points = gt_coords.reshape(-1, 2)\n",
    "\n",
    "#     # ----------------------------------------------------\n",
    "#     # Simulate ground truth coupler motion\n",
    "#     # ----------------------------------------------------\n",
    "#     sim_req = {\n",
    "#         \"params\": gt_points.tolist(),\n",
    "#         \"type\": gt_mech_name,\n",
    "#         \"speedScale\": speedscale,\n",
    "#         \"steps\": steps,\n",
    "#         \"relativeTolerance\": 0.1,\n",
    "#     }\n",
    "#     try:\n",
    "#         resp = requests.post(API_ENDPOINT, headers=HEADERS, data=json.dumps([sim_req])).json()\n",
    "#         P = np.array(resp[0][\"poses\"]) if isinstance(resp, list) and \"poses\" in resp[0] else None\n",
    "#     except:\n",
    "#         continue\n",
    "\n",
    "#     if P is None or P.shape[0] < minsteps:\n",
    "#         continue\n",
    "\n",
    "#     coup_idx = coupler_index_for(gt_mech_name)\n",
    "#     if coup_idx < 0:\n",
    "#         continue\n",
    "\n",
    "#     original_x = P[:, coup_idx, 0]\n",
    "#     original_y = P[:, coup_idx, 1]\n",
    "\n",
    "#     # Normalization parameters\n",
    "#     orig_phi = -get_pca_inclination(original_x, original_y)\n",
    "#     orig_denom = np.sqrt(np.var(original_x) + np.var(original_y)) + 1e-8\n",
    "#     ox_mean, oy_mean = np.mean(original_x), np.mean(original_y)\n",
    "\n",
    "#     # Store predictions\n",
    "#     all_predicted_points = {}\n",
    "\n",
    "#     # ============================================================\n",
    "#     # Loop: all mechanisms Ã— temperatures\n",
    "#     # ============================================================\n",
    "#     temperatures = [0.0, 0.5, 1.0, 1.5, 2.0, 4.0, 10.0]\n",
    "\n",
    "#     for mech_idx in range(NUM_MECH_TYPES):\n",
    "#         mech_name = index_to_label[str(mech_idx)]\n",
    "#         mech_safe = safe_name(mech_name)\n",
    "\n",
    "#         for temp in temperatures:\n",
    "#             temp_str = temp_to_str(temp)\n",
    "\n",
    "#             # ----------------------------------------------------\n",
    "#             # Predict joints\n",
    "#             # ----------------------------------------------------\n",
    "#             pred_tokens = predict_autoregressive_latent(\n",
    "#                 model, latent, mech_idx, tgt_seq_len,\n",
    "#                 device, temperature=temp, top_k=None\n",
    "#             )\n",
    "#             coord_tokens = [t for t in pred_tokens if t >= BIN_OFFSET]\n",
    "#             if len(coord_tokens) < 4:\n",
    "#                 continue\n",
    "\n",
    "#             coords_float = binner.bin_to_value_torch(\n",
    "#                 torch.tensor(coord_tokens, device=device) - BIN_OFFSET\n",
    "#             ).cpu().numpy()\n",
    "\n",
    "#             if coords_float.size % 2 == 1:\n",
    "#                 coords_float = coords_float[:-1]\n",
    "\n",
    "#             pred_points = coords_float.reshape(-1, 2)\n",
    "#             all_predicted_points[f\"{mech_safe}_t{temp_str}\"] = pred_points\n",
    "\n",
    "#             # ----------------------------------------------------\n",
    "#             # Simulate predicted mechanism\n",
    "#             # ----------------------------------------------------\n",
    "#             sim_req_pred = {\n",
    "#                 \"params\": pred_points.tolist(),\n",
    "#                 \"type\": mech_name,\n",
    "#                 \"speedScale\": speedscale,\n",
    "#                 \"steps\": steps,\n",
    "#                 \"relativeTolerance\": 0.1,\n",
    "#             }\n",
    "#             try:\n",
    "#                 resp_p = requests.post(API_ENDPOINT, headers=HEADERS, data=json.dumps([sim_req_pred])).json()\n",
    "#                 Pp = np.array(resp_p[0][\"poses\"]) if isinstance(resp_p, list) and \"poses\" in resp_p[0] else None\n",
    "#             except:\n",
    "#                 continue\n",
    "\n",
    "#             if Pp is None or Pp.shape[0] < minsteps:\n",
    "#                 continue\n",
    "\n",
    "#             coup_idx_pred = coupler_index_for(mech_name)\n",
    "#             if coup_idx_pred < 0:\n",
    "#                 continue\n",
    "\n",
    "#             gen_x = Pp[:, coup_idx_pred, 0]\n",
    "#             gen_y = Pp[:, coup_idx_pred, 1]\n",
    "\n",
    "#             # ----------------------------------------------------\n",
    "#             # Align predicted coupler to GT\n",
    "#             # ----------------------------------------------------\n",
    "#             gen_phi = -get_pca_inclination(gen_x, gen_y)\n",
    "#             rotation = gen_phi - orig_phi\n",
    "#             gen_x, gen_y = rotate_curve(gen_x, gen_y, rotation)\n",
    "\n",
    "#             gen_denom = np.sqrt(np.var(gen_x) + np.var(gen_y)) + 1e-8\n",
    "#             scale = orig_denom / gen_denom\n",
    "#             gen_x *= scale\n",
    "#             gen_y *= scale\n",
    "\n",
    "#             gen_x -= (np.mean(gen_x) - ox_mean)\n",
    "#             gen_y -= (np.mean(gen_y) - oy_mean)\n",
    "\n",
    "#             # ----------------------------------------------------\n",
    "#             # PLOT WITH **JOINT NUMBERING**\n",
    "#             # ----------------------------------------------------\n",
    "#             plt.figure(figsize=(6, 6))\n",
    "#             plt.plot(original_x, original_y, \"r-\", label=f\"GT ({gt_mech_name})\")\n",
    "#             plt.plot(gen_x, gen_y, \"g--\", label=f\"Pred {mech_name} t={temp}\")\n",
    "\n",
    "#             # GT joints (numbered)\n",
    "#             plt.scatter(gt_points[:, 0], gt_points[:, 1], c=\"red\", s=50)\n",
    "#             for j, (xj, yj) in enumerate(gt_points):\n",
    "#                 plt.text(xj + 0.003, yj + 0.003, f\"{j}\", fontsize=9, color=\"red\")\n",
    "\n",
    "#             # Predicted joints (numbered)\n",
    "#             for j, (xp, yp) in enumerate(pred_points):\n",
    "#                 plt.scatter(xp, yp, c=\"green\", s=50)\n",
    "#                 plt.text(xp + 0.003, yp + 0.003, f\"{j}\", fontsize=8, color=\"green\")\n",
    "\n",
    "#             plt.axis(\"equal\")\n",
    "#             plt.legend()\n",
    "#             plt.tight_layout()\n",
    "\n",
    "#             save_path = os.path.join(sample_dir, f\"{mech_safe}_t{temp_str}.png\")\n",
    "#             plt.savefig(save_path)\n",
    "#             plt.close()\n",
    "\n",
    "#     # ============================================================\n",
    "#     # FINAL: Combined joint scatter plot (numbered)\n",
    "#     # ============================================================\n",
    "#     if len(all_predicted_points) == 0:\n",
    "#         continue\n",
    "\n",
    "#     plt.figure(figsize=(8, 8))\n",
    "\n",
    "#     # GT numbered\n",
    "#     plt.scatter(gt_points[:, 0], gt_points[:, 1], c=\"red\", s=90, edgecolor=\"black\")\n",
    "#     for j, (x, y) in enumerate(gt_points):\n",
    "#         plt.text(x + 0.005, y + 0.005, f\"{j}\", color=\"red\", fontsize=10)\n",
    "\n",
    "#     max_joints = max(pts.shape[0] for pts in all_predicted_points.values())\n",
    "#     cmap = plt.cm.get_cmap(\"tab10\", max_joints)\n",
    "\n",
    "#     for mech_key, pts in all_predicted_points.items():\n",
    "#         for j in range(pts.shape[0]):\n",
    "#             color = cmap(j % max_joints)\n",
    "#             xj, yj = pts[j]\n",
    "#             plt.scatter(xj, yj, color=color, s=40)\n",
    "#             plt.text(xj + 0.003, yj + 0.003, f\"{j}\", fontsize=8, color=color)\n",
    "\n",
    "#     plt.axis(\"equal\")\n",
    "#     plt.title(f\"Predicted Joints â€” Sample {i} â€” GT={gt_mech_name}\")\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     out_path = os.path.join(sample_dir, \"all_predicted_joints_colored.png\")\n",
    "#     plt.savefig(out_path, dpi=200)\n",
    "#     plt.close()\n",
    "\n",
    "#     print(f\"Saved: {out_path}\")\n",
    "\n",
    "# print(\"DONE.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
